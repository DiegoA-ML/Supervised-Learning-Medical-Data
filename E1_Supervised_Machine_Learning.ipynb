{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Supervised Machine Learning - Algorithm Exploration and Comparison\n",
        "---"
      ],
      "metadata": {
        "id": "fqcYDErsm-Fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Code:\n",
        "\n",
        "https://colab.research.google.com/drive/1ORbMohKEgPkOFgJHiIZKrwLYxROeo-HE?usp=sharing\n",
        "\n",
        "Database utilized:\n",
        "\n",
        "https://drive.google.com/drive/folders/1vXBUIWBS3_-Ez0LzCYEcOx2SzWQv0bwU"
      ],
      "metadata": {
        "id": "wycZORTpKjji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description\n",
        "---\n",
        "\n",
        "The database we used for this project is called 'Heart Disease'. The database contains 14 columns with information on age, sex, type of chest pain, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise-induced angina, ST depression induced by exercise relative to rest, the slope of the peak exercise ST segment, thalassemia, and our categorical variable indicating the severity of heart disease.\n",
        "\n",
        "1. **age**: Age in years\n",
        "2. **sex**: Sex (1 = male; 0 = female)\n",
        "3. **cp**: Chest pain type\n",
        "   - Value 1: Typical angina\n",
        "   - Value 2: Atypical angina\n",
        "   - Value 3: Non-anginal pain\n",
        "   - Value 4: Asymptomatic\n",
        "4. **trestbps**: Resting blood pressure (in mm Hg on admission to the hospital)\n",
        "5. **chol**: Serum cholesterol in mg/dl\n",
        "6. **fbs**: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
        "7. **restecg**: Resting electrocardiographic results\n",
        "   - Value 0: Normal\n",
        "   - Value 1: Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "   - Value 2: Showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "8. **thalach**: Maximum heart rate achieved\n",
        "9. **exang**: Exercise-induced angina (1 = yes; 0 = no)\n",
        "10. **oldpeak**: ST depression induced by exercise relative to rest\n",
        "11. **slope**: The slope of the peak exercise ST segment\n",
        "    - Value 1: Upsloping\n",
        "    - Value 2: Flat\n",
        "    - Value 3: Downsloping\n",
        "12. **ca**: Number of major vessels (0-3) colored by fluoroscopy\n",
        "13. **thal**: Thalassemia\n",
        "    - Value 3: Normal\n",
        "    - Value 6: Fixed defect\n",
        "    - Value 7: Reversible defect\n",
        "14. **num**: Diagnosis of heart disease (angiographic disease status)\n",
        "    - Value 0: Absence of heart disease\n",
        "    - Value 1, 2, 3, 4: Varying degrees of presence and severity\n"
      ],
      "metadata": {
        "id": "_MqDCGEFN0wQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "3f1OMUNYXnXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.utils import check_random_state, check_array\n",
        "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR, _libsvm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "\n"
      ],
      "metadata": {
        "id": "Cv3op1HdXqQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We previously replaced the null values with the median of the column.\n",
        "\n",
        "# Import \"heart_disease\" Database.\n",
        "#df_path = \"/content/heart_disease.csv\"\n",
        "df_path = \"/content/dataset.csv\"\n",
        "\n",
        "df_heart_disease = pd.read_csv(df_path)\n"
      ],
      "metadata": {
        "id": "Que4CotBXOo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Look at the Database"
      ],
      "metadata": {
        "id": "DH0QtWwIY7ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we show the first 5 lines of the database.\n",
        "df_heart_disease.head()"
      ],
      "metadata": {
        "id": "xmMbWTX2Y9-0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e0b476c5-77c1-4f89-85cd-de34b397d615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
              "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
              "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
              "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
              "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
              "\n",
              "    ca  thal  num  \n",
              "0  0.0   6.0    0  \n",
              "1  3.0   3.0    2  \n",
              "2  2.0   7.0    1  \n",
              "3  0.0   3.0    0  \n",
              "4  0.0   3.0    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99cf25b5-65ed-4514-ac72-6e2ba74731be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99cf25b5-65ed-4514-ac72-6e2ba74731be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99cf25b5-65ed-4514-ac72-6e2ba74731be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99cf25b5-65ed-4514-ac72-6e2ba74731be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84e210be-2294-4881-919b-178229b814cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84e210be-2294-4881-919b-178229b814cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84e210be-2294-4881-919b-178229b814cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_heart_disease",
              "summary": "{\n  \"name\": \"df_heart_disease\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          61,\n          64,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          124,\n          192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          321,\n          187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          170,\n          114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          2.4,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.934375462234502,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9383826733563154,\n        \"min\": 3.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Information"
      ],
      "metadata": {
        "id": "BLxBDzuOZe4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic stadistic information.\n",
        "df_heart_disease.describe()"
      ],
      "metadata": {
        "id": "2eXe6iG7ZK6u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d6baa966-6af0-42da-fdae-3767d9ddd024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age         sex          cp    trestbps        chol         fbs  \\\n",
              "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
              "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
              "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
              "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
              "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
              "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
              "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
              "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
              "\n",
              "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
              "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
              "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.663366   \n",
              "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.934375   \n",
              "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
              "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
              "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
              "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
              "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
              "\n",
              "             thal         num  \n",
              "count  303.000000  303.000000  \n",
              "mean     4.722772    0.937294  \n",
              "std      1.938383    1.228536  \n",
              "min      3.000000    0.000000  \n",
              "25%      3.000000    0.000000  \n",
              "50%      3.000000    0.000000  \n",
              "75%      7.000000    2.000000  \n",
              "max      7.000000    4.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84c80103-9f1c-478f-9bab-befdc19433cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.438944</td>\n",
              "      <td>0.679868</td>\n",
              "      <td>3.158416</td>\n",
              "      <td>131.689769</td>\n",
              "      <td>246.693069</td>\n",
              "      <td>0.148515</td>\n",
              "      <td>0.990099</td>\n",
              "      <td>149.607261</td>\n",
              "      <td>0.326733</td>\n",
              "      <td>1.039604</td>\n",
              "      <td>1.600660</td>\n",
              "      <td>0.663366</td>\n",
              "      <td>4.722772</td>\n",
              "      <td>0.937294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.038662</td>\n",
              "      <td>0.467299</td>\n",
              "      <td>0.960126</td>\n",
              "      <td>17.599748</td>\n",
              "      <td>51.776918</td>\n",
              "      <td>0.356198</td>\n",
              "      <td>0.994971</td>\n",
              "      <td>22.875003</td>\n",
              "      <td>0.469794</td>\n",
              "      <td>1.161075</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>0.934375</td>\n",
              "      <td>1.938383</td>\n",
              "      <td>1.228536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>564.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84c80103-9f1c-478f-9bab-befdc19433cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84c80103-9f1c-478f-9bab-befdc19433cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84c80103-9f1c-478f-9bab-befdc19433cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a468b8a-9bb1-43ea-8ab5-b7d052f06d35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a468b8a-9bb1-43ea-8ab5-b7d052f06d35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a468b8a-9bb1-43ea-8ab5-b7d052f06d35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_heart_disease\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92.5728159022223,\n        \"min\": 9.038662442446746,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          54.43894389438944,\n          56.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.91803123915392,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6798679867986799,\n          1.0,\n          0.46729882777012993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.16755832732339,\n        \"min\": 0.9601256119600138,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          3.1584158415841586,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82.63751582423215,\n        \"min\": 17.59974772958769,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          131.68976897689768,\n          130.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 150.36559430635785,\n        \"min\": 51.77691754263704,\n        \"max\": 564.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          246.69306930693068,\n          241.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.0512286741478,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1485148514851485,\n          1.0,\n          0.35619787492797644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.77655393236438,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          0.9900990099009901,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.71042641207808,\n        \"min\": 22.875003276980376,\n        \"max\": 303.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          149.6072607260726,\n          153.0,\n          303.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.9862394088184,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.32673267326732675,\n          1.0,\n          0.46979446452231655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.59952466080658,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          303.0,\n          1.0396039603960396,\n          1.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.5627986546393,\n        \"min\": 0.6162261453459619,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          1.6006600660066006,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.8485191634673,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          0.6633663366336634,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.6457229231865,\n        \"min\": 1.9383826733563154,\n        \"max\": 303.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.7227722772277225,\n          7.0,\n          1.9383826733563154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.72284943779034,\n        \"min\": 0.0,\n        \"max\": 303.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          303.0,\n          0.9372937293729373,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Database shape.\n",
        "shape = df_heart_disease.shape\n",
        "print(f\"The database has the shape: {shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBtMBcGJYK_4",
        "outputId": "9a2cc543-9a9a-4364-abb6-ada1698684d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The database has the shape: (303, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Description\n",
        "---\n",
        "Machine learning is at the forefront of medical research, aiding in the identification of diseases and the diagnosis of conditions. According to a 2015 report published by Pharmaceutical Research and Manufacturers of America, more than 800 drugs and vaccines were being tested to treat cancer. In an interview with Bloomberg Technology, Jeff Tyner, a researcher at the Knight Institute, stated that while this is exciting, it also presents the challenge of finding ways to work with all the resulting data. \"That's where the idea of biologists and doctors working with data scientists and computer scientists is very important,\" said Tyner.\n",
        "\n",
        "In this document we try to diagnose the presence and severity of a heart disease, with the use of machine learning algorithms such as, decision tree, logistic regression, K-nearest neighbor, and support vector machine. We show the algorithm generated from scratch and compare it with the algorithm generated by scikit-learn."
      ],
      "metadata": {
        "id": "rvPfAWbCZ1Ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation\n",
        "---"
      ],
      "metadata": {
        "id": "0mWEG48Ra8LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spliting the Data"
      ],
      "metadata": {
        "id": "4d2__13ubDxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we split the data.\n",
        "X, y = df_heart_disease.iloc[:, :-1], df_heart_disease.iloc[:, -1]\n",
        "y = pd.Series(LabelEncoder().fit_transform(y))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "hQPx8M0rYLv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "---\n",
        "A Decision Tree is a supervised learning algorithm used in machine learning for classification. This model is represented by roots and leafs, and the paths from the roots to the leafs represents classification rules. And each leaf node represents a class label.\n",
        "\n",
        "One of the advantages of Decision Trees is that they are intuitive and easy to interpret. However, they can be prone to overfitting if not properly configured, for example if they are allowed to grow too much."
      ],
      "metadata": {
        "id": "msahi_IFbT6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        ''' Constructor to initialize a node'''\n",
        "\n",
        "        # For decision node\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "\n",
        "        # for leaf node\n",
        "        self.value = value\n",
        "\n",
        "\n",
        "class MyDecisionTreeClassifier():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        ''' Constructor to initialize the decision tree'''\n",
        "\n",
        "        self.root = None  # root node of the tree\n",
        "        self.min_samples_split = min_samples_split    # minimum number of samples required to split an internal node\n",
        "        self.max_depth = max_depth    # maximum depth of the tree\n",
        "\n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        ''' Recursive function to build the tree '''\n",
        "\n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]  # split the dataset into features and labels\n",
        "        num_samples, num_features = np.shape(X)  # get the number of samples and features\n",
        "        num_labels = len(np.unique(Y))  # get the number of labels#\n",
        "\n",
        "        # Check if the current node can be split further\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # Find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "\n",
        "            # If a valid split is found\n",
        "            if best_split[\"info_gain\"]>0:\n",
        "                # Build the left and right subtrees recursively\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "                # Return the current node with left and right subtrees\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        # If splitting is not possible, create a leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        ''' Function to find the best split for the dataset '''\n",
        "\n",
        "\n",
        "        best_split = {} # Dictionary to store the best split\n",
        "        max_info_gain = -float(\"inf\")  # Initialize maximum information gain\n",
        "\n",
        "        # Iterate over all features\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]  # Get all values of the feature\n",
        "            possible_thresholds = np.unique(feature_values) # Get unique threshold values\n",
        "\n",
        "            # Iterate over all possible thresholds\n",
        "            for threshold in possible_thresholds:\n",
        "                # Split the dataset based on the threshold\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # Check if both splits are non-empty\n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # Calculate information gain\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "\n",
        "                    # Update the best split if current information gain is greater\n",
        "                    if curr_info_gain>max_info_gain:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"info_gain\"] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        ''' Function to split the data '''\n",
        "\n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        return dataset_left, dataset_right\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "        ''' Function to split the dataset based on a feature and threshold '''\n",
        "\n",
        "        weight_l = len(l_child) / len(parent) # Left child\n",
        "        weight_r = len(r_child) / len(parent)# Right child\n",
        "        if mode==\"gini\":\n",
        "          # Calculate information gain using Gini index\n",
        "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
        "        else:\n",
        "          # Calculate information gain using entropy\n",
        "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
        "        return gain\n",
        "\n",
        "    def entropy(self, y):\n",
        "        ''' Function to compute entropy '''\n",
        "\n",
        "        class_labels = np.unique(y)   # Get unique class labels\n",
        "        entropy = 0\n",
        "\n",
        "        # Calculate entropy\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y) # Proportion of class label\n",
        "            entropy += -p_cls * np.log2(p_cls)\n",
        "        return entropy\n",
        "\n",
        "    def gini_index(self, y):\n",
        "        ''' Function to compute gini index '''\n",
        "\n",
        "        class_labels = np.unique(y) # Get unique class labels\n",
        "        gini = 0\n",
        "\n",
        "        # Calculate Gini index\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            gini += p_cls**2\n",
        "        return 1 - gini\n",
        "\n",
        "    def calculate_leaf_value(self, Y):\n",
        "        ''' Function to compute leaf node '''\n",
        "\n",
        "        Y = list(Y)\n",
        "        return max(Y, key=Y.count) # Return the most common class label\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        ''' Function to print the tree '''\n",
        "\n",
        "        if not tree:\n",
        "            tree = self.root # Start from the root node if no tree is provided\n",
        "\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent) # Print left subtree\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)  # Print right subtree\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        ''' Function to train the tree '''\n",
        "\n",
        "        dataset = np.concatenate((X, Y), axis=1)  # Concatenate features and labels\n",
        "        self.root = self.build_tree(dataset)  # Build the tree\n",
        "\n",
        "    def predict(self, X):\n",
        "        ''' Function to predict new dataset '''\n",
        "\n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]  # Predict for each sample\n",
        "        return preditions\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "        ''' Function to predict a single data point '''\n",
        "\n",
        "        if tree.value!=None: return tree.value  # Return value if leaf node\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)"
      ],
      "metadata": {
        "id": "EEMGUO_SiOUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill the NA values with the median of the column\n",
        "for columna in df_heart_disease.columns:\n",
        "    mediana = df_heart_disease[columna].median()\n",
        "    df_heart_disease[columna].fillna(mediana, inplace=True)"
      ],
      "metadata": {
        "id": "_fcchFqfbse9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits the dataset in train and test, also Y is reshaped\n",
        "X = df_heart_disease.iloc[:, :-1].values\n",
        "Y = df_heart_disease.iloc[:, -1].values.reshape(-1,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
      ],
      "metadata": {
        "id": "qT2vXmQ2VVQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MyDecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.print_tree()"
      ],
      "metadata": {
        "id": "I38YQ48SggsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5f9940-0b5a-4d78-9de9-0151bc2c0ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_12 <= 3.0 ? 0.08453547529659733\n",
            " left:X_11 <= 0.0 ? 0.052931165315667106\n",
            "  left:X_0 <= 57.0 ? 0.02229400148528221\n",
            "    left:X_9 <= 3.0 ? 0.02932012648809519\n",
            "        left:0.0\n",
            "        right:1.0\n",
            "    right:X_7 <= 71.0 ? 0.05565003779289479\n",
            "        left:2.0\n",
            "        right:0.0\n",
            "  right:X_2 <= 3.0 ? 0.0807426192041577\n",
            "    left:X_4 <= 236.0 ? 0.07369614512471656\n",
            "        left:0.0\n",
            "        right:0.0\n",
            "    right:X_9 <= 2.0 ? 0.12918871252204578\n",
            "        left:1.0\n",
            "        right:3.0\n",
            " right:X_9 <= 0.8 ? 0.0631670972928784\n",
            "  left:X_4 <= 240.0 ? 0.09022973640275589\n",
            "    left:X_3 <= 135.0 ? 0.10583333333333333\n",
            "        left:0.0\n",
            "        right:1.0\n",
            "    right:X_2 <= 3.0 ? 0.07804032766225577\n",
            "        left:0.0\n",
            "        right:1.0\n",
            "  right:X_7 <= 132.0 ? 0.04064612664902878\n",
            "    left:X_3 <= 144.0 ? 0.06625043357613591\n",
            "        left:3.0\n",
            "        right:4.0\n",
            "    right:X_7 <= 147.0 ? 0.10449928693171939\n",
            "        left:2.0\n",
            "        right:0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "precision = precision_score(Y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(Y_test, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(Y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "Zw0WdjoAhgs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be0ace0-a276-4814-fc87-795ec8451d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6229508196721312\n",
            "Precision: 0.57472359893252\n",
            "F1: 0.5967476463229968\n",
            "Confusion Matrix:\n",
            "[[35  3  2  0  0]\n",
            " [ 6  0  0  4  1]\n",
            " [ 2  1  0  0  0]\n",
            " [ 0  1  3  2  0]\n",
            " [ 0  0  0  0  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SKLearn Decision Tree"
      ],
      "metadata": {
        "id": "bIivLHMli0bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lassifier = DecisionTreeClassifier()\n",
        "lassifier.fit(X_train, Y_train)\n",
        "predictions = lassifier.predict(X_test)"
      ],
      "metadata": {
        "id": "rRo14q86jIjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(Y_test, predictions)\n",
        "precision = precision_score(Y_test, predictions, average='weighted')\n",
        "f1 = f1_score(Y_test, predictions, average='weighted')\n",
        "conf_matrix = confusion_matrix(Y_test, predictions)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "lLDNX_T_izmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f21d9e-6f2d-4b10-82eb-2cd9e56e2963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5245901639344263\n",
            "Precision: 0.6284729284464874\n",
            "F1: 0.5646848302932347\n",
            "Confusion Matrix:\n",
            "[[26  7  6  1  0]\n",
            " [ 4  3  0  3  1]\n",
            " [ 1  2  0  0  0]\n",
            " [ 0  1  1  2  2]\n",
            " [ 0  0  0  0  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "cv_results1 = cross_validate(lassifier, X_train, Y_train, cv=5, scoring=scoring)\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(\"Accuracy: \", np.mean(cv_results1['test_accuracy']))\n",
        "print(\"Precision:\", np.mean(cv_results1['test_precision']))\n",
        "print(\"Recall:   \", np.mean(cv_results1['test_recall']))\n",
        "print(\"F1-score: \", np.mean(cv_results1['test_f1']))\n",
        "\n",
        "# Train the model on the full training set\n",
        "lassifier.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions1 = lassifier.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics on the test set\n",
        "accuracy = accuracy_score(Y_test, predictions1)\n",
        "precision = precision_score(Y_test, predictions1, average='weighted')\n",
        "recall = recall_score(Y_test, predictions1, average='weighted')\n",
        "f1 = f1_score(Y_test, predictions1, average='weighted')\n",
        "conf_matrix1 = confusion_matrix(Y_test, predictions1)\n",
        "\n",
        "# Print evaluation metrics on the test set\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ZXm-HuRAKm",
        "outputId": "634b2950-0c8c-4db5-e3b1-d6f1eea3b50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Results:\n",
            "Accuracy:  0.40867346938775506\n",
            "Precision: 0.4444803928686964\n",
            "Recall:    0.40867346938775506\n",
            "F1-score:  0.41654457542299594\n",
            "\n",
            "Test Set Evaluation Metrics:\n",
            "Accuracy: 0.5573770491803278\n",
            "Precision: 0.6077733741668168\n",
            "Recall: 0.5573770491803278\n",
            "F1-score: 0.5762295081967211\n",
            "Confusion Matrix:\n",
            "[[30  5  5  0  0]\n",
            " [ 4  3  1  2  1]\n",
            " [ 1  2  0  0  0]\n",
            " [ 0  3  1  0  2]\n",
            " [ 0  0  0  0  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree Comparison and Conclusion\n",
        "---\n",
        "**Result Comparison**\\\n",
        "\n",
        "*DT accuracy*: 0.6230\\\n",
        "*sk DT accuracy*: 0.5245\n",
        "\n",
        "*DT F1-score*: 0.5967\\\n",
        "*sk DT F1-score*: 0.5646\n",
        "\n",
        "**Conclusion**\\\n",
        "The Decision Tree from scratch outperforms the Decision Tree from sklearn in therms of accuracy and F1-scorde. Higher accuracy means that the model makes fewer mistakes. In this case, the DT from scratch has an accuracy of 0.6230, which is higher than the sklearn DT accuracy of 0.5245.\n",
        "In terms of F1-score a higher F1-score indicates better performance. The DT from scratch has 0.5967, which is higher but no much than DT from sklearn, with an F1-score of 0.5646.\n",
        "In conclusion, the DT from scratch seems to perform better than the sklearn DT model.And this is more evident if we do cross validation, which the results show us that it radically decreases the accuracy with 4087 and an F1-score of 0.4165"
      ],
      "metadata": {
        "id": "SRNkstFfMdRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "---\n",
        "Logistic Regression is a supervised machine learning algorithm used for binary classification tasks. It models the probability of a binary outcome using a logistic function (sigmoid function). The algorithm estimates the relationship between a dependent binary variable and one or more independent variables by fitting a logistic curve to the data. It outputs probabilities that can be converted to binary decisions, making it useful for tasks like spam detection, medical diagnosis, and credit scoring."
      ],
      "metadata": {
        "id": "2cGdqgj8bZb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Implementation\n",
        "class MyLogisticRegression:\n",
        "    def __init__(self, alpha=0.01, num_iters=1000):\n",
        "        self.alpha = alpha\n",
        "        self.num_iters = num_iters\n",
        "        self.theta = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def compute_cost(self, X, y):\n",
        "        m = len(y)\n",
        "        h = self.sigmoid(X.dot(self.theta))\n",
        "        cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "        return cost\n",
        "\n",
        "    def gradient_descent(self, X, y):\n",
        "        m = len(y)\n",
        "        self.theta = np.zeros(X.shape[1])\n",
        "        cost_history = []\n",
        "\n",
        "        for _ in range(self.num_iters):\n",
        "            h = self.sigmoid(X.dot(self.theta))\n",
        "            gradient = (1/m) * X.T.dot(h - y)\n",
        "            self.theta = self.theta - self.alpha * gradient\n",
        "            cost = self.compute_cost(X, y)\n",
        "            cost_history.append(cost)\n",
        "\n",
        "        return self.theta, cost_history\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "        self.theta, self.cost_history = self.gradient_descent(X_bias, y)\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        X_bias = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "        return self.sigmoid(X_bias.dot(self.theta))\n",
        "\n",
        "    def predict(self, X):\n",
        "        prob = self.predict_prob(X)\n",
        "        return [1 if p >= 0.5 else 0 for p in prob]"
      ],
      "metadata": {
        "id": "G4Gj0Ur9dHV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Q0SXo9Zci5V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLogisticRegression(alpha=0.01, num_iters=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Dpq175FAi7zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6257f9-3804-4c32-ef3c-658a1ebfadd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-97eae066d7e6>:14: RuntimeWarning: divide by zero encountered in log\n",
            "  cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model and make predictions on the  dataset ...\n",
        "# Calculate Precission\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Show Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Show Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "t5qBAw47jCYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad4ebe0-e7c0-4d26-8f76-3f64d2f38b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 48.35%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.70      0.73        47\n",
            "           1       0.23      0.58      0.33        19\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.00      0.00      0.00         9\n",
            "           4       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.48        91\n",
            "   macro avg       0.20      0.26      0.21        91\n",
            "weighted avg       0.44      0.48      0.45        91\n",
            "\n",
            "Confusion Matrix:\n",
            "[[33 14  0  0  0]\n",
            " [ 8 11  0  0  0]\n",
            " [ 1 11  0  0  0]\n",
            " [ 1  8  0  0  0]\n",
            " [ 0  4  0  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SkLearn Logistic Regression\n"
      ],
      "metadata": {
        "id": "4wGKfAyUoH-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bXDSaVJem56i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "20165be5-6f01-480e-97db-6fdfcc165d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Display the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "UXw8PP_Nm_Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5450d4a2-6709-4dc0-e9df-96781479ec10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.24%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.91      0.80        47\n",
            "           1       0.36      0.21      0.27        19\n",
            "           2       0.50      0.08      0.14        12\n",
            "           3       0.28      0.56      0.37         9\n",
            "           4       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.58        91\n",
            "   macro avg       0.37      0.35      0.32        91\n",
            "weighted avg       0.54      0.58      0.53        91\n",
            "\n",
            "Confusion Matrix:\n",
            "[[43  2  1  1  0]\n",
            " [11  4  0  4  0]\n",
            " [ 3  2  1  6  0]\n",
            " [ 2  2  0  5  0]\n",
            " [ 1  1  0  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Comparison and Conclusion\n",
        "---\n",
        "**Result Comparison**\\\n",
        "\n",
        "*DT accuracy*: 0.4835\\\n",
        "*sk DT accuracy*: 0.5824\n",
        "\n",
        "\n",
        "**Conclusion**\\\n",
        "In this comparison, the logistic regression model implemented using scikit-learn achieved better performance with an accuracy of 58.24% compared to the from-scratch implementation, which achieved an accuracy of 48.35%. In summary, the scikit-learn logistic regression model would be the recommended choice for predicting heart disease due to its better performance and ease of use."
      ],
      "metadata": {
        "id": "K3EIf0jkosKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "---\n",
        " It is a versatile supervised learning algorithm used for classification and regression tasks. It classifies data points based on the majority class among their nearest neighbors (for classification) or predicts values based on the average of nearest neighbors (for regression). It doesn't require explicit training, instead, it memorizes the entire training dataset."
      ],
      "metadata": {
        "id": "sp5Y-OgcbdXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors Implementation\n",
        "class MyKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = StandardScaler().fit_transform(X_train)\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "        predictions = []\n",
        "        for x_test in X_test_scaled:\n",
        "            distances = []\n",
        "            for i, x_train in enumerate(self.X_train):\n",
        "                distance = self.euclidean_distance(x_test, x_train)\n",
        "                distances.append((i, distance))\n",
        "            distances.sort(key=lambda x: x[1])\n",
        "            neighbors = [i for i, _ in distances[:self.k]]\n",
        "            labels = [self.y_train[i] for i in neighbors]\n",
        "            prediction = max(set(labels), key=labels.count)\n",
        "            predictions.append(prediction)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "Aed40sCabk80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of MyKNN\n",
        "knn_model = MyKNN()"
      ],
      "metadata": {
        "id": "KFkkf0-wn9AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "knn_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dEHrIyqDn_eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = knn_model.predict(X_test)"
      ],
      "metadata": {
        "id": "xDGGNs-NoCRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix of the model\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate precision, recall, and F1-score with average='weighted'\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "print(\"Precision (weighted):\", precision)\n",
        "print(\"Recall (weighted):\", recall)\n",
        "print(\"F1-score (weighted):\", f1)\n"
      ],
      "metadata": {
        "id": "blHMNjEToFvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb571e6-6ea1-4bee-8559-6e2b90203808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6153846153846154\n",
            "Confusion Matrix:\n",
            "[[45  2  0  0  0]\n",
            " [11  6  2  0  0]\n",
            " [ 3  4  3  2  0]\n",
            " [ 1  4  2  2  0]\n",
            " [ 1  1  1  1  0]]\n",
            "Precision (weighted): 0.5437144340712325\n",
            "Recall (weighted): 0.6153846153846154\n",
            "F1-score (weighted): 0.567817896389325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  SKlearn K-Nearest Neighbor"
      ],
      "metadata": {
        "id": "WF4zoZLpqiFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "folquX33pCUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of KNeighborsClassifier - (scikit learn)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = knn_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "C9XTgOYAo4cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "Lb9qRAxgo_Db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf51a2c-07e9-46a4-8be0-c6a8a1ca6ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6373626373626373\n",
            "Precision: 0.5591204430490144\n",
            "Recall: 0.6373626373626373\n",
            "F1-score: 0.5834473219088603\n",
            "Confusion Matrix:\n",
            "[[46  1  0  0  0]\n",
            " [11  7  0  1  0]\n",
            " [ 4  3  4  1  0]\n",
            " [ 1  4  3  1  0]\n",
            " [ 1  1  1  1  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation KNN"
      ],
      "metadata": {
        "id": "Ghm86EMJwRHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross-validation\n",
        "# Define scoring metrics\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "cv_results = cross_validate(knn_model, X_train_scaled, y_train, cv=5, scoring=scoring)\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(\"Accuracy: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:   \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score: \", np.mean(cv_results['test_f1']))\n",
        "\n",
        "# Train the model on the full training set\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics on the test set\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print evaluation metrics on the test set\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaEeh0wuwBi-",
        "outputId": "4b5834f6-b36a-4704-fa71-01a76c2878e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Results:\n",
            "Accuracy:  0.5895902547065337\n",
            "Precision: 0.5272558721430298\n",
            "Recall:    0.5895902547065337\n",
            "F1-score:  0.5411714643911797\n",
            "\n",
            "Test Set Evaluation Metrics:\n",
            "Accuracy: 0.6373626373626373\n",
            "Precision: 0.5591204430490144\n",
            "Recall: 0.6373626373626373\n",
            "F1-score: 0.5834473219088603\n",
            "Confusion Matrix:\n",
            "[[46  1  0  0  0]\n",
            " [11  7  0  1  0]\n",
            " [ 4  3  4  1  0]\n",
            " [ 1  4  3  1  0]\n",
            " [ 1  1  1  1  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor Comparison and Conclusion\n",
        "---\n",
        "**Result Comparison**\\\n",
        "\n",
        "*DT accuracy*: 0.6153\\\n",
        "*sk DT accuracy*: 0.6373\n",
        "\n",
        "\n",
        "**Conclusion**\\\n",
        "As we can see the scikit-learn implementation of K-Nearest Neighbor outperforms the from-scratch implementation, showing higher precision, recall, and F1-score. Therefore, for this classification task, using the scikit-learn implementation would be preferred due to its better performance and reliability."
      ],
      "metadata": {
        "id": "SCgRj9bzqWQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine\n",
        "---\n",
        "The main idea of SVM (Support Vector Machine) is to find the hyperplane or line that best separates the classes, and the samples closest to the separating hyperplane are called support vectors. The best class separation would be the one that maximizes the distance between the support vectors and the separating hyperplane. This distance is called the margin."
      ],
      "metadata": {
        "id": "z3HynYE4bmXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM:\n",
        "    def __init__(self, regression=False, C=1.0, eps=0, learning_rate=0.001, max_iter=1000,\n",
        "                 random_state=0):\n",
        "        self.regression = regression\n",
        "        self.C = C\n",
        "        self.eps = eps\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.regression:\n",
        "            self.bias, self.weights = self._find_weights(X, y)\n",
        "        else:\n",
        "            classes = np.unique(y)\n",
        "            n_classes = len(classes)\n",
        "            _, n_features = X.shape\n",
        "\n",
        "            self.bias = np.zeros(n_classes)\n",
        "            self.weights = np.zeros((n_classes, n_features))\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "            for i, cls in enumerate(classes):\n",
        "                y_binary = np.where(y == cls, 1, -1)\n",
        "                self.bias[i], self.weights[i] = self._find_weights(X, y_binary)\n",
        "\n",
        "    def _find_weights(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        bias = 0\n",
        "        weights = np.zeros(n_features) if self.regression else np.random.randn(n_features)\n",
        "\n",
        "        for _ in range(self.max_iter):\n",
        "            for i in range(n_samples):\n",
        "                y_pred = X[i] @ weights + bias\n",
        "                margin = y[i] - y_pred if self.regression else y[i] * y_pred\n",
        "                condition = np.abs(margin) > self.eps if self.regression else margin < 1\n",
        "\n",
        "                if condition:\n",
        "                    if self.regression:\n",
        "                        db = -self.C * (margin - self.eps)\n",
        "                        dw = -self.C * (margin - self.eps) * X[i]\n",
        "                    else:\n",
        "                        db = -self.C * y[i]\n",
        "                        dw = -self.C * y[i] * X[i]\n",
        "\n",
        "                    bias -= self.learning_rate * db\n",
        "                    weights -= self.learning_rate * dw\n",
        "\n",
        "        return bias, weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = X @ self.weights.T + self.bias\n",
        "\n",
        "        return scores if self.regression else np.argmax(scores, axis=1)"
      ],
      "metadata": {
        "id": "6PFbLCxuW-4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianSVM:\n",
        "    # Initialization method for the GaussianSVM class\n",
        "    def __init__(self, regression=False, C=1.0, kernel='rbf', degree=3, solver='auto',\n",
        "                 gamma='scale', epsilon=0.1, coef0=0.0, shrinking=True, probability=False,\n",
        "                 tol=0.001, cache_size=200, max_iter=-1, random_state=None):\n",
        "        # Store whether the SVM is for regression or classification\n",
        "        self.regression = regression\n",
        "        # Regularization parameter\n",
        "        self.C = C\n",
        "        # Kernel type (e.g., 'rbf', 'linear')\n",
        "        self.kernel = kernel\n",
        "        # Degree for polynomial kernel\n",
        "        self.degree = degree\n",
        "        # Solver type (e.g., 'auto', 'c_svc')\n",
        "        self.solver = solver\n",
        "        # Kernel coefficient\n",
        "        self.gamma = gamma\n",
        "        # Epsilon margin for regression\n",
        "        self.epsilon = epsilon\n",
        "        # Independent term in kernel function\n",
        "        self.coef0 = coef0\n",
        "        # Whether to use the shrinking heuristic\n",
        "        self.shrinking = shrinking\n",
        "        # Whether to enable probability estimates\n",
        "        self.probability = probability\n",
        "        # Tolerance for stopping criterion\n",
        "        self.tol = tol\n",
        "        # Cache size in MB\n",
        "        self.cache_size = cache_size\n",
        "        # Maximum number of iterations (-1 for no limit)\n",
        "        self.max_iter = max_iter\n",
        "        # Seed for random number generation to ensure reproducibility\n",
        "        self.random_state = random_state\n",
        "\n",
        "    # Method to fit the model to the data\n",
        "    def fit(self, X, y):\n",
        "        # Ensure the input data is of type float64\n",
        "        X = X.astype(np.float64)\n",
        "        y = y.astype(np.float64)\n",
        "\n",
        "        # Get a random state based on the given random seed\n",
        "        rnd = check_random_state(self.random_state)\n",
        "        seed = rnd.randint(np.iinfo('i').max)\n",
        "\n",
        "        # Set gamma value based on input parameter\n",
        "        if self.gamma == 'scale':\n",
        "            # Gamma is 1 / (number of features * variance of X)\n",
        "            self.gamma = 1.0 / (X.shape[1] * X.var()) if X.var() != 0 else 1.0\n",
        "        elif self.gamma == 'auto':\n",
        "            # Gamma is 1 / number of features\n",
        "            self.gamma = 1.0 / X.shape[1]\n",
        "        else:\n",
        "            # Use the provided gamma value\n",
        "            self.gamma = self.gamma\n",
        "\n",
        "        # Automatically select the solver if set to 'auto'\n",
        "        if self.solver == 'auto':\n",
        "            # Use 'epsilon_svr' for regression, 'c_svc' for classification\n",
        "            self.solver = 'epsilon_svr' if self.regression else 'c_svc'\n",
        "\n",
        "        # List of supported solver implementations\n",
        "        libsvm_impl = ['c_svc', 'nu_svc', 'one_class', 'epsilon_svr', 'nu_svr']\n",
        "        # Get the index of the solver in the implementation list\n",
        "        self.solver = libsvm_impl.index(self.solver)\n",
        "\n",
        "        # Call the internal _libsvm fit function to train the model\n",
        "        (self.support_, self.support_vectors_, self._n_support, self.dual_coef_, self.intercept_,\n",
        "         self._probA, self._probB, self.fit_status_, self._num_iter\n",
        "        ) = _libsvm.fit(X, y, C=self.C, svm_type=self.solver, kernel=self.kernel, gamma=self.gamma,\n",
        "                        degree=self.degree, epsilon=self.epsilon, coef0=self.coef0, tol=self.tol,\n",
        "                        shrinking=self.shrinking, probability=self.probability,\n",
        "                        cache_size=self.cache_size, max_iter=self.max_iter, random_seed=seed\n",
        "                        )\n",
        "\n",
        "    # Method to make predictions using the trained model\n",
        "    def predict(self, X_test):\n",
        "        # Ensure the input data is of type float64\n",
        "        X_test = X_test.astype(np.float64)\n",
        "        # Call the internal _libsvm predict function to get predictions\n",
        "        prediction = _libsvm.predict(X_test, self.support_, self.support_vectors_, self._n_support,\n",
        "                                     self.dual_coef_, self.intercept_, self._probA, self._probB,\n",
        "                                     svm_type=self.solver, kernel=self.kernel, degree=self.degree,\n",
        "                                     coef0=self.coef0, gamma=self.gamma, cache_size=self.cache_size\n",
        "                                     )\n",
        "\n",
        "        # Return prediction directly for regression, convert to int for classification\n",
        "        return prediction if self.regression else prediction.astype(int)"
      ],
      "metadata": {
        "id": "ZUl2MeBb5nm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVC\n",
        "\n",
        "linear_svc = LinearSVM(random_state=0)\n",
        "linear_svc.fit(X_train, y_train)\n",
        "linear_svc_pred_res = linear_svc.predict(X_test)\n",
        "linear_svc_accuracy = accuracy_score(y_test, linear_svc_pred_res)\n",
        "\n",
        "print(f'LinearSVC accuracy: {linear_svc_accuracy:}')\n",
        "print(linear_svc_pred_res)"
      ],
      "metadata": {
        "id": "S3Tf04N86Qjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVC - (scikit-learn)\n",
        "\n",
        "sk_linear_svc = LinearSVC(loss='squared_hinge', max_iter=10000, random_state=0)\n",
        "sk_linear_svc.fit(X_train, y_train)\n",
        "sk_linear_svc_pred_res = sk_linear_svc.predict(X_test)\n",
        "sk_linear_svc_accuracy = accuracy_score(y_test, sk_linear_svc_pred_res)\n",
        "\n",
        "print(f'sk LinearSVC accuracy: {sk_linear_svc_accuracy:}')\n",
        "print(sk_linear_svc_pred_res)"
      ],
      "metadata": {
        "id": "NEL-Tuzi6j3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GaussianSVC\n",
        "\n",
        "svc = GaussianSVM(random_state=0, gamma='auto')\n",
        "svc.fit(X_train, y_train)\n",
        "svc_pred_res = svc.predict(X_test)\n",
        "svc_accuracy = accuracy_score(y_test, svc_pred_res)\n",
        "\n",
        "print(f'SVC accuracy: {svc_accuracy:}')\n",
        "print(svc_pred_res)"
      ],
      "metadata": {
        "id": "pmZYZWfx6-S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GaussianSVC - (scikit-learn)\n",
        "\n",
        "sk_svc = GaussianSVM(random_state=0, gamma='auto')\n",
        "sk_svc.fit(X_train, y_train)\n",
        "sk_svc_pred_res = sk_svc.predict(X_test)\n",
        "sk_svc_accuracy = accuracy_score(y_test, sk_svc_pred_res)\n",
        "\n",
        "print(f'sk SVC accuracy: {sk_svc_accuracy:}')\n",
        "print(sk_svc_pred_res)"
      ],
      "metadata": {
        "id": "8_2vVqZs9z0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine Comparison and Conclusion\n",
        "---\n",
        "**Result Comparison**\\\n",
        "*LinearSVC accuracy*: 0.275\\\n",
        "*sk LinearSVC accuracy*: 0.286\n",
        "\n",
        "*SVC accuracy*: 0.516\\\n",
        "*sk SVC accuracy*: 0.516\n",
        "\n",
        "\n",
        "**Conclusion**\\\n",
        "A Support Vector Machine algorithm is essentially a quadratic programming problem, meaning it is an optimization problem. In the code, only the linear and Gaussian kernels are used, but we can notice that with the Gaussian kernel, the results are 'better'; however, all the values delivered by the Gaussian kernel are purely zeros, and the accuracy result it provides (around 0.5) is assumed to be because half of the original data are 0. The linear kernel has better results because, unlike the Gaussian kernel, it gives different results than 0, but it has lower accuracy performance.\n",
        "\n",
        "The results with the scikit-learn library are very similar as we can see, and the phenomenon of zero results with the Gaussian kernel remains, and the accuracy level with the linear kernel is maintained."
      ],
      "metadata": {
        "id": "r19780JDwV2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "---\n",
        "\n",
        "As you can see, each of the models shows different performance, both for learning and from scratch. As for the models with the best performance in accuracy from sklearn, it was K-Nearest Neighbor with a value of 0.637 and a cross-validation of 0.5896. While the model from scratch with the best performance was Decision Tree, which had an accuracy value of 0.623. This can be explained as possibly caused by overfitting or model optimization. In general, the model that obtained the best performance was K-Nearest Neighbor, since although it did not have the highest value in the from scratch model it was very close to that result, and comparing its F1-score values, the best model was K-Nearest Neighbor with a value of 0.5678 in terms of models from scratch. And the same model but from sklearn was the best in its area, with a value in its F1-score of 0.5834"
      ],
      "metadata": {
        "id": "K66pqccRg4Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "---\n",
        "Egazakharenko. (2024, May 12). Support Vector Machines (SVM) from scratch. Kaggle. https://www.kaggle.com/code/egazakharenko/support-vector-machines-svm-from-scratch/notebook\n",
        "\n",
        "Normalized Nerd. (2021, January 21). Decision Tree Classification in Python (from scratch!). Recovered on June 14, 2024. Recovered from https://youtu.be/sgQAhG5Q7iY?si=GYp66yb51L9CIT4Q\n",
        "\n",
        "IBM. What is a decision tree?. Recovered on June 14, 2024. Recovered from https://www.ibm.com/topics/decision-trees"
      ],
      "metadata": {
        "id": "QyE_TVBRA2s7"
      }
    }
  ]
}